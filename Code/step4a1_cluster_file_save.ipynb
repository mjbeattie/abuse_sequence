{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NSDUH Drug Sequence Analysis Part 4a1:  Cluster File Save\n",
    "## Matthew J. Beattie\n",
    "## University of Oklahoma\n",
    "__December 30, 2021__\n",
    "\n",
    "### Databricks File Preparation\n",
    "This file generates cluster labels for $B$ runs of KMC and saves the data to .txt for uploading into Databricks.  It also stores demographic information, but that isn't used in Databricks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import python modules\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import pathlib, itertools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import random\n",
    "from sklearn_extra import cluster as cs\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import json\n",
    "import pathutils as pu\n",
    "#import scipy.stats as stats\n",
    "from scipy.spatial.distance import euclidean\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from collections import Counter\n",
    "import profile\n",
    "import gc\n",
    "import csv\n",
    "\n",
    "HOME_DIR = pathlib.Path.home()\n",
    "CW_DIR = pathlib.Path.cwd()\n",
    "\n",
    "FIGW = 12\n",
    "FIGH = 5\n",
    "FONTSIZE = 8\n",
    "FIGURESIZE = (FIGW,FIGH)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (FIGW, FIGH)\n",
    "plt.rcParams['font.size'] = FONTSIZE\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in model, set file names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "datapath = 'C:/Users/mjbea/OneDrive/GitHub/abuse_sequence/Data3/'\n",
    "workingpath = 'C:/Users/mjbea/OneDrive/GitHub/abuse_sequence/Code3/'\n",
    "outpath = 'C:/Users/mjbea/OneDrive/GitHub/abuse_sequence/Output3/'\n",
    "year = '2016_2017_2018_2019'\n",
    "jsondict = datapath + 'NSDUH_field.json'\n",
    "n_clusters = 11\n",
    "\n",
    "hugefiles = 'C:/Users/mjbea/huge_files/'\n",
    "\n",
    "# Setup filenames\n",
    "clustpkl = workingpath + 'Kmeans_' + str(n_clusters) + 'clust_' + str(year) + '_nonullpath_clust.pkl'\n",
    "demogpkl = workingpath + 'Kmeans_' + str(n_clusters) + 'clust_' + str(year) + '_nonullpath_demog.pkl'\n",
    "\n",
    "# Read in cluster and demographic information and the model\n",
    "dfclust = pd.read_pickle(clustpkl)\n",
    "#dfclust = dfclust[['RESPID', 'AFUVECT']]\n",
    "dfdemog = pd.read_pickle(demogpkl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESPID</th>\n",
       "      <th>AFUVECT</th>\n",
       "      <th>YRWEIGHT</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201611635143.0</td>\n",
       "      <td>[0, 16, 15, 20, 991, 991, 991, 991, 991, 991]</td>\n",
       "      <td>204.858562</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201635755143.0</td>\n",
       "      <td>[0, 26, 16, 991, 991, 991, 991, 991, 991, 991]</td>\n",
       "      <td>2533.458396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201692675143.0</td>\n",
       "      <td>[0, 5, 18, 32, 34, 991, 991, 991, 991, 991]</td>\n",
       "      <td>6203.973093</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201659596143.0</td>\n",
       "      <td>[0, 991, 14, 991, 991, 991, 991, 991, 991, 991]</td>\n",
       "      <td>1386.672703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201641106143.0</td>\n",
       "      <td>[0, 991, 991, 991, 991, 991, 991, 991, 991, 991]</td>\n",
       "      <td>2384.841656</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RESPID                                           AFUVECT  \\\n",
       "0  201611635143.0     [0, 16, 15, 20, 991, 991, 991, 991, 991, 991]   \n",
       "1  201635755143.0    [0, 26, 16, 991, 991, 991, 991, 991, 991, 991]   \n",
       "2  201692675143.0       [0, 5, 18, 32, 34, 991, 991, 991, 991, 991]   \n",
       "3  201659596143.0   [0, 991, 14, 991, 991, 991, 991, 991, 991, 991]   \n",
       "4  201641106143.0  [0, 991, 991, 991, 991, 991, 991, 991, 991, 991]   \n",
       "\n",
       "      YRWEIGHT  labels  \n",
       "0   204.858562       3  \n",
       "1  2533.458396       0  \n",
       "2  6203.973093      10  \n",
       "3  1386.672703       2  \n",
       "4  2384.841656       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfclust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170944, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfclust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calcinertia()\n",
    "Calculates the total inertia of a dataset given the data, cluster centers,\n",
    "and labels from the model.\n",
    "\"\"\"\n",
    "def calcinertia(df, centers):\n",
    "    df['afuarray'] = df.apply(lambda row: np.array(row['AFUVECT']), axis=1)\n",
    "    df['center'] = df.apply(lambda row: centers[row['labels']], axis=1)\n",
    "    df['dist'] = df.apply(lambda row: euclidean(row['afuarray'],row['center']), axis=1)\n",
    "    df['distsq'] = df.apply(lambda row: row['dist']**2, axis=1)\n",
    "    return df['distsq'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate clusters\n",
    "Generate _B_ cluster sets using _k-means_ on a fraction of the original dataset.  Merge the cluster results back into the original dataset to create a dataframe with the respondent ID, the AFU vector, and the assignments of the observations to cluster sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inertia is: 10207984350.876812 \n",
      "Execution time was: 317.11638021469116\n"
     ]
    }
   ],
   "source": [
    "# Set clustering process parameters\n",
    "B = 20   # Number of models to generate\n",
    "fraction = 0.3  # Input dataset fraction of original total\n",
    "f = 0.8  # Fraction of input dataset to use for model construction\n",
    "n_init = 10\n",
    "max_iter = 1000\n",
    "tol = 0.0001\n",
    "\n",
    "# Reduce master dataset if desired and save as an array for KNN\n",
    "if fraction < 0.9:\n",
    "    dfclust = dfclust.sample(frac=fraction, replace = False)\n",
    "allarray = np.array(list(dfclust['AFUVECT']))\n",
    "\n",
    "inertialist = []\n",
    "starttime = time.time()\n",
    "try:\n",
    "    for i in range(0,B):\n",
    "        # Sample the dfclust dataset\n",
    "        clustsamp = dfclust.sample(frac=f, replace=False)\n",
    "        clustsamp = clustsamp[['RESPID', 'AFUVECT', 'YRWEIGHT']]\n",
    "\n",
    "        # Using k-means, generate a model and label the sample dataset\n",
    "        samparray = np.array(list(clustsamp['AFUVECT']))\n",
    "        weights = np.array(list(clustsamp['YRWEIGHT']))\n",
    "\n",
    "        model = KMeans(n_clusters=n_clusters, init='k-means++', n_init=n_init, max_iter=max_iter, \n",
    "                       tol=tol, verbose=0, random_state=None, copy_x=True, algorithm='auto')\n",
    "        model.fit(samparray, sample_weight=weights)\n",
    "\n",
    "        # Apply model to entire dataset to generate clusters\n",
    "        preds = model.predict(allarray)\n",
    "\n",
    "        # Add labels to original dataframe\n",
    "        colname = 'labels_' + str(i)\n",
    "        dfclust[colname] = preds\n",
    "\n",
    "        # Calculate inertia of labelled total dataset\n",
    "        tempdf = dfclust[['AFUVECT']].copy()\n",
    "        tempdf.loc[:,'labels'] = preds.copy()\n",
    "        inertia = calcinertia(tempdf, model.cluster_centers_)\n",
    "        inertialist.append(inertia)\n",
    "\n",
    "    meaninertia = np.array(inertialist).mean()\n",
    "    clustertime = time.time() - starttime\n",
    "    print('Mean inertia is:', meaninertia, '\\nExecution time was:', clustertime)\n",
    "\n",
    "except:\n",
    "    print('Clustering process failed --', sys.exc_info()[0], \"occurred.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files to CSV for work in Azure Databricks\n",
    "clustcsv = datapath + 'dfclust30pct.txt'\n",
    "dfclust.to_csv(clustcsv, sep='\\t', encoding='utf-8', index=False)\n",
    "\n",
    "demogcsv = datapath + 'dfdemog.txt'\n",
    "dfdemog.to_csv(demogcsv, sep='\\t', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
