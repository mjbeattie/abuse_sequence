{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSDUH Drug Sequence Analysis Part 2:  Clustering\n",
    "## Matthew J. Beattie\n",
    "## University of Oklahoma\n",
    "__November 23, 2021__\n",
    "\n",
    "This notebook examines drug use pathways with clustering.\n",
    "\n",
    "## Clustering the drug use pathways\n",
    "In the previous notebook, we stored drug use pathways as adjacency matrices of weighted directed graphs.  In this notebook, we seek to find groupings of similar pathways.  We will do this using _k-means clustering_ as implemented by SciKit Learn Extra.  We were limited to this choice due to the memory required to store the distance matrix during the SciKit _k-medoids_ method.\n",
    "\n",
    "There are 9 drugs that we consider in the pathways, most of which have an age-of-first-use recorded value.  Several, including prescription opioid abuse, can have imputed values.  For each respondent, we create a 1x10 vector (_AFUVECT_), each position of which is the AFU for the drug (plus one for 'start').  We then cluster these vectors.\n",
    "\n",
    "### No null pathways\n",
    "In previous experiments, the cluster that had _no substance use_ dominated the other clusters.  When the null pathway is included as a cluster, it acts as a catch-all for any pathways that don't begin with common substances.  Consequently, this experiment only considers respondents who have had some lifetime substance use.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import python modules\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import pathlib, itertools\n",
    "import time as timelib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "#from sklearn.impute import KNNImputer\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "from sklearn_extra import cluster as cs\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import json\n",
    "import pathutils as pu\n",
    "import scipy.stats as stats\n",
    "from math import dist\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "HOME_DIR = pathlib.Path.home()\n",
    "CW_DIR = pathlib.Path.cwd()\n",
    "\n",
    "FIGW = 12\n",
    "FIGH = 5\n",
    "FONTSIZE = 8\n",
    "FIGURESIZE = (FIGW,FIGH)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (FIGW, FIGH)\n",
    "plt.rcParams['font.size'] = FONTSIZE\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE\n",
    "\n",
    "random.seed(660806)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set experiment parameters\n",
    "The experiment parameters are the year of the survey (unless it is a block of years), the number of clusters, and the name of the JSON dictionary file.  Determining the best number of K-Medoid clusters is computationally complex and too slow in a notebook on a PC or cloud VM.  We run an experiment that seeks to minimize inertia based upon number of clusters and maximum interations.  We rerun the K-means algorithm and change the number of clusters.  We then plot the inertia versus the number of clusters and look for an elbow in the curve.\n",
    "\n",
    "The parameter _readpickle_ tells the script whether to calculate the clusters or accept them from a prior run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "datapath = 'C:/Users/mjbea/OneDrive/GitHub/abuse_sequence/Data3/'\n",
    "workingpath = 'C:/Users/mjbea/OneDrive/GitHub/abuse_sequence/Code3/'\n",
    "outpath = 'C:/Users/mjbea/OneDrive/GitHub/abuse_sequence/Output3/'\n",
    "year = '2016_2017_2018_2019'\n",
    "jsondict = datapath + 'NSDUH_field.json'\n",
    "readpickle = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "Read in NSDUH data using _pathutils.py_ user-defined functions.  Data read in includes:\n",
    "* NSDUH data from the prior script, _step1_sequence_dataprep_multiyear.ipynb_ \n",
    "* Dictionaries of drug names and their reference indices\n",
    "* JSON file containing the reference indices and names for values of the NSDUH variables\n",
    "* _Demographics_ are defined as the set of NSDUH variables for comparisons\n",
    "\n",
    "The data is then stored as two dataframes, each of which uses the NSDUH respondent ID (_RESPID_) as a key value.  One dataframe, _dfclust_ includes the RESPID and pathway data.  The second, _dfdemog_, includes the RESPID and demographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in NSDUH data into a pandas dataframe\n",
    "\"\"\"\n",
    "# Read datafiles\n",
    "loadfname = datapath + 'NSDUH_' + str(year) + '_pathways.pkl'\n",
    "nsduh2 = pd.read_pickle(loadfname)\n",
    "\n",
    "# Drug name and indices are called by a user-defined function.\n",
    "ident, rawafuvals, afuvals, drugnames, drugorder, drugnums, drugposition, startdemog, demographics = pu.surveyvars(year)\n",
    "\n",
    "# These are the demographic column names from NSDUH (or SVCFLAG for SERVICE)\n",
    "#demographics = ['CATAG6','SVCFLAG','IRSEX','IRMARIT','NEWRACE2','EDUHIGHCAT','IRWRKSTAT','GOVTPROG','INCOME','COUTYP4','AIIND102','RESPID']\n",
    "\n",
    "# Decode dictionaries for NSDUH variables:\n",
    "f1 = open(jsondict, 'r')\n",
    "nsduhDecoder = json.load(f1)\n",
    "f1.close()\n",
    "nsduh2.head()\n",
    "\n",
    "# Add the yearly average sample weight to the demographics list\n",
    "demographics.remove('ANALWT_C')\n",
    "demographics.append('YRWEIGHT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRALCAGE</th>\n",
       "      <th>IRMJAGE</th>\n",
       "      <th>IRHERAGE</th>\n",
       "      <th>IRHALLUCAGE</th>\n",
       "      <th>IRINHALAGE</th>\n",
       "      <th>IRMETHAMAGE</th>\n",
       "      <th>AGE2</th>\n",
       "      <th>CATAG6</th>\n",
       "      <th>IRSEX</th>\n",
       "      <th>IRMARIT</th>\n",
       "      <th>...</th>\n",
       "      <th>AIIND102</th>\n",
       "      <th>RESPID</th>\n",
       "      <th>SVCFLAG</th>\n",
       "      <th>IRTOBAGE</th>\n",
       "      <th>IRCOC2AGE</th>\n",
       "      <th>YRWEIGHT</th>\n",
       "      <th>IRSCRIPAGE</th>\n",
       "      <th>AFUPATH</th>\n",
       "      <th>AFUVECT</th>\n",
       "      <th>UNWAFUPATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [IRALCAGE, IRMJAGE, IRHERAGE, IRHALLUCAGE, IRINHALAGE, IRMETHAMAGE, AGE2, CATAG6, IRSEX, IRMARIT, NEWRACE2, EDUHIGHCAT, IRWRKSTAT, GOVTPROG, INCOME, COUTYP4, AIIND102, RESPID, SVCFLAG, IRTOBAGE, IRCOC2AGE, YRWEIGHT, IRSCRIPAGE, AFUPATH, AFUVECT, UNWAFUPATH]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsduh2[nsduh2['RESPID']=='201953777216']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE2</th>\n",
       "      <th>SVCFLAG</th>\n",
       "      <th>CATAG6</th>\n",
       "      <th>IRSEX</th>\n",
       "      <th>IRMARIT</th>\n",
       "      <th>NEWRACE2</th>\n",
       "      <th>EDUHIGHCAT</th>\n",
       "      <th>IRWRKSTAT</th>\n",
       "      <th>GOVTPROG</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>COUTYP4</th>\n",
       "      <th>AIIND102</th>\n",
       "      <th>RESPID</th>\n",
       "      <th>YRWEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>201611635143.0</td>\n",
       "      <td>204.858562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>201635755143.0</td>\n",
       "      <td>2533.458396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>201692675143.0</td>\n",
       "      <td>6203.973093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>201659596143.0</td>\n",
       "      <td>1386.672703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>201641106143.0</td>\n",
       "      <td>2384.841656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE2  SVCFLAG  CATAG6  IRSEX  IRMARIT  NEWRACE2  EDUHIGHCAT  IRWRKSTAT  \\\n",
       "0    14        0       3      2        1         1           4          4   \n",
       "2    15        0       4      1        1         7           1          3   \n",
       "3    17        0       6      2        1         1           3          2   \n",
       "4    13        0       3      1        1         5           4          4   \n",
       "5    16        0       5      1        2         1           2          4   \n",
       "\n",
       "   GOVTPROG  INCOME  COUTYP4  AIIND102          RESPID     YRWEIGHT  \n",
       "0         2       4        3         2  201611635143.0   204.858562  \n",
       "2         2       2        1         2  201635755143.0  2533.458396  \n",
       "3         2       3        1         2  201692675143.0  6203.973093  \n",
       "4         2       2        2         2  201659596143.0  1386.672703  \n",
       "5         2       2        2         2  201641106143.0  2384.841656  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the dataset into two smaller ones to work with\n",
    "dfdemog = nsduh2[demographics]\n",
    "dfdemog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESPID</th>\n",
       "      <th>AFUVECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201611635143.0</td>\n",
       "      <td>[0, 16, 15, 20, 991, 991, 991, 991, 991, 991]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201635755143.0</td>\n",
       "      <td>[0, 26, 16, 991, 991, 991, 991, 991, 991, 991]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201692675143.0</td>\n",
       "      <td>[0, 5, 18, 32, 34, 991, 991, 991, 991, 991]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201659596143.0</td>\n",
       "      <td>[0, 991, 14, 991, 991, 991, 991, 991, 991, 991]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201641106143.0</td>\n",
       "      <td>[0, 991, 991, 991, 991, 991, 991, 991, 991, 991]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RESPID                                           AFUVECT\n",
       "0  201611635143.0     [0, 16, 15, 20, 991, 991, 991, 991, 991, 991]\n",
       "2  201635755143.0    [0, 26, 16, 991, 991, 991, 991, 991, 991, 991]\n",
       "3  201692675143.0       [0, 5, 18, 32, 34, 991, 991, 991, 991, 991]\n",
       "4  201659596143.0   [0, 991, 14, 991, 991, 991, 991, 991, 991, 991]\n",
       "5  201641106143.0  [0, 991, 991, 991, 991, 991, 991, 991, 991, 991]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfclust = nsduh2[['RESPID','AFUVECT']]\n",
    "dfclust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dfclust and dfdemog dataframes to match the observations and split back into\n",
    "# final dfclust and dfdemog.  This avoids NA values due to a RESPID mismatch.\n",
    "merged_total = pd.merge(dfclust, dfdemog, on=['RESPID'])\n",
    "dfclust = merged_total[['RESPID','AFUVECT','YRWEIGHT']]\n",
    "dfdemog = merged_total[['RESPID', 'CATAG6', 'SVCFLAG', 'IRSEX', 'IRMARIT', 'NEWRACE2', 'EDUHIGHCAT', 'IRWRKSTAT',\n",
    "       'GOVTPROG', 'INCOME', 'COUTYP4', 'AIIND102','YRWEIGHT']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "K-Medoids fails because the SKLearn version requires storing the entire n x n distance matrix into memory.  The 100k+ x 100k+ matrix is too large to do that.  So we run KNN instead.  We set the number of clusters at 16 based upon runs from one year of data.\n",
    "\n",
    "### Simplify Cluster Definition\n",
    "K-Means is used for clustering because the SKLearn implementation can run without storing the inter-observation distance matrix into memory.  However, the centers of the clusters are difficult to interpret because they are _means_.  We try to simplify the definitions using two methods.  First, we round the cluster centers to integers.  Second, we find the _medoid_ of the clusters.  These values are written to file out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:786: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25). It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\mjbea\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\core\\frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Create an array of the PATHVECT values for input into SciKit KMeans()\n",
    "patharray = np.array(list(dfclust['AFUVECT']))\n",
    "weights = np.array(list(dfclust['YRWEIGHT']))\n",
    "\n",
    "# Initialize mlflow and run experiment\n",
    "#clustrange = [1,2,3,4,5,6,7,8,9,10]\n",
    "#clustrange = [11,12,13,14,15,16,17,18,19,20]\n",
    "clustrange = [21,22,23,24,25,26,27,28,29,30]\n",
    "n_init = 20\n",
    "max_iter = 1000\n",
    "tol = 0.0001\n",
    "\n",
    "# Setup mlflow experiment\n",
    "experiment_name = \"Kmeans Clusters from 21-30\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "for i in clustrange:\n",
    "    n_clusters = i\n",
    "\n",
    "    # Setup filenames\n",
    "    descout = outpath + 'Kmeans_' + str(n_clusters) + 'clust_' + str(year) + '_nonullpath_clustdesc.txt'\n",
    "    modpkl = workingpath + 'Kmeans_' + str(n_clusters) + 'clust_' + str(year) + '_nonullpath_model.pkl'\n",
    "    clustpkl = workingpath + 'Kmeans_' + str(n_clusters) + 'clust_' + str(year) + '_nonullpath_clust.pkl'\n",
    "    demogpkl = workingpath + 'Kmeans_' + str(n_clusters) + 'clust_' + str(year) + '_nonullpath_demog.pkl'\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Calculate clusters and save model to a pickle file (or load model)\n",
    "        if readpickle != True:\n",
    "            model = KMeans(n_clusters=n_clusters, init='k-means++', n_init=n_init, max_iter=max_iter, \n",
    "                           tol=tol, verbose=0, random_state=None, copy_x=True, algorithm='auto')\n",
    "            model.fit(patharray, sample_weight=weights)\n",
    "            pickle.dump(model, open(modpkl, 'wb'))\n",
    "        else:\n",
    "            model = pickle.load(open(modpkl, 'rb'))\n",
    "\n",
    "        pred = model.predict(patharray)\n",
    "\n",
    "        # Append labels to the dfdemog dataset\n",
    "        dfdemog['labels'] = model.labels_\n",
    "        dfclust['labels'] = model.labels_\n",
    "\n",
    "        # Store parameters and metrics into mlflow\n",
    "        mlflow.log_param(\"n_clusters\", n_clusters)\n",
    "        mlflow.log_param(\"n_init\", n_init)\n",
    "        mlflow.log_param(\"max_iter\", max_iter)\n",
    "        mlflow.log_param(\"tol\", tol)\n",
    "        mlflow.log_metric(\"inertia\", model.inertia_)\n",
    "\n",
    "        # Generate medoids of clusters\n",
    "        medoids = []\n",
    "        for j in range(0, len(model.cluster_centers_)):\n",
    "            clustcenter = model.cluster_centers_[j]\n",
    "            clust = dfclust[dfclust['labels']==j]\n",
    "            clust['distfrommean'] = clust.apply(lambda row: dist(np.array(row['AFUVECT']), clustcenter), axis=1)\n",
    "            medoids.append(clust.loc[clust['distfrommean'].idxmin()]['AFUVECT'])\n",
    "        medoids = np.array(medoids)\n",
    "\n",
    "        # Print cluster descriptions to a file\n",
    "        f = open(descout, 'w')\n",
    "        print('\\n******\\nDRUG VECTOR POSITIONS\\n*****\\n', file=f)\n",
    "        print(drugnums, file=f)\n",
    "        print('\\n******\\nCLUSTER CENTERS\\n******\\n', file=f)\n",
    "        print(model.cluster_centers_, file=f)\n",
    "        print('\\n******\\n INTEGER CLUSTER CENTERS\\n******\\n', file=f)\n",
    "        print(np.array(model.cluster_centers_, dtype='int'), file=f)\n",
    "        print('\\n******\\n CLUSTER MEDOIDS\\n******\\n', file=f)\n",
    "        print(medoids, file=f)\n",
    "        print('\\n******\\nCLUSTER ITERATIONS\\n******\\n', file=f)\n",
    "        print(model.n_iter_, file=f)\n",
    "        print('\\n******\\nCLUSTER INERTIA\\n******\\n', file=f)\n",
    "        print(model.inertia_, file=f)\n",
    "        print('\\n*****\\nFRACTION OF POPULATION FOR EACH CLUSTER\\n*****\\n', file=f)\n",
    "        totweight = clustpkl['YRWEIGHT'].sum()\n",
    "        clustfracs = clustpkl.groupby(['labels']).sum('YRWEIGHT')/totweight\n",
    "        print(clustfracs, file=f)\n",
    "        f.close()\n",
    "\n",
    "        mlflow.log_artifact(descout)\n",
    "        \n",
    "        # Get json file with variable definitions\n",
    "        f1 = open(jsondict, 'r')\n",
    "        nsduhDecoder = json.load(f1)\n",
    "        f1.close()\n",
    "\n",
    "        ident, rawafuvals, afuvals, drugnames, drugorder, drugnums, drugposition, startdemog, demographics = pu.surveyvars(year)\n",
    "\n",
    "        # Save datasets to pickle files for future use\n",
    "        dfclust.to_pickle(clustpkl)\n",
    "        mlflow.log_artifact(clustpkl)\n",
    "        dfdemog.to_pickle(demogpkl)\n",
    "        mlflow.log_artifact(demogpkl)\n",
    "        mlflow.log_artifact(modpkl)\n",
    "\n",
    "    # End mlflow run\n",
    "    mlflow.end_run()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustpkl = pd.read_pickle(workingpath + 'Kmeans_11clust_2016_2017_2018_2019_nonullpath_clust.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESPID</th>\n",
       "      <th>AFUVECT</th>\n",
       "      <th>YRWEIGHT</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201611635143.0</td>\n",
       "      <td>[0, 16, 15, 20, 991, 991, 991, 991, 991, 991]</td>\n",
       "      <td>204.858562</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201635755143.0</td>\n",
       "      <td>[0, 26, 16, 991, 991, 991, 991, 991, 991, 991]</td>\n",
       "      <td>2533.458396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201692675143.0</td>\n",
       "      <td>[0, 5, 18, 32, 34, 991, 991, 991, 991, 991]</td>\n",
       "      <td>6203.973093</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201659596143.0</td>\n",
       "      <td>[0, 991, 14, 991, 991, 991, 991, 991, 991, 991]</td>\n",
       "      <td>1386.672703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201641106143.0</td>\n",
       "      <td>[0, 991, 991, 991, 991, 991, 991, 991, 991, 991]</td>\n",
       "      <td>2384.841656</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RESPID                                           AFUVECT  \\\n",
       "0  201611635143.0     [0, 16, 15, 20, 991, 991, 991, 991, 991, 991]   \n",
       "1  201635755143.0    [0, 26, 16, 991, 991, 991, 991, 991, 991, 991]   \n",
       "2  201692675143.0       [0, 5, 18, 32, 34, 991, 991, 991, 991, 991]   \n",
       "3  201659596143.0   [0, 991, 14, 991, 991, 991, 991, 991, 991, 991]   \n",
       "4  201641106143.0  [0, 991, 991, 991, 991, 991, 991, 991, 991, 991]   \n",
       "\n",
       "      YRWEIGHT  labels  \n",
       "0   204.858562       3  \n",
       "1  2533.458396       0  \n",
       "2  6203.973093      10  \n",
       "3  1386.672703       2  \n",
       "4  2384.841656       5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustpkl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of population for each cluster\n",
      "        YRWEIGHT\n",
      "labels          \n",
      "0       0.209984\n",
      "1       0.047161\n",
      "2       0.173413\n",
      "3       0.193789\n",
      "4       0.054712\n",
      "5       0.109234\n",
      "6       0.063096\n",
      "7       0.046583\n",
      "8       0.028427\n",
      "9       0.029279\n",
      "10      0.044321\n"
     ]
    }
   ],
   "source": [
    "print('Fraction of population for each cluster')\n",
    "totweight = clustpkl['YRWEIGHT'].sum()\n",
    "clustfracs = clustpkl.groupby(['labels']).sum('YRWEIGHT')/totweight\n",
    "print(clustfracs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
